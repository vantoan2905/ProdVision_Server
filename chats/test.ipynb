{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9078d4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/miniconda3/envs/tomkey/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[33mChecking connectivity to the model hosters, this may take a while. To bypass this check, set `DISABLE_MODEL_SOURCE_CHECK` to `True`.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from paddleocr import LayoutDetection, TableCellsDetection, TextDetection, TextRecognition\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d01a351d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layout_model():\n",
    "    return LayoutDetection(model_name=\"PP-DocLayoutV2\")\n",
    "\n",
    "def get_table_model():\n",
    "    return TableCellsDetection(model_name=\"RT-DETR-L_wired_table_cell_det\")\n",
    "\n",
    "def get_text_det_model():\n",
    "    return TextDetection(device=\"gpu\",model_name=\"PP-OCRv5_server_det\")\n",
    "\n",
    "def get_text_rec_model():\n",
    "    return TextRecognition(device=\"gpu\", model_name=\"PP-OCRv5_mobile_rec\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caaca722",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/miniconda3/envs/tomkey/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:718: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
      "  warnings.warn(warning_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paddle version: 3.2.0\n",
      "Is compiled with CUDA: True\n",
      "CUDA device count: 1\n",
      "Current device: gpu:0\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "\n",
    "print(\"Paddle version:\", paddle.__version__)\n",
    "print(\"Is compiled with CUDA:\", paddle.is_compiled_with_cuda())\n",
    "print(\"CUDA device count:\", paddle.device.cuda.device_count())\n",
    "print(\"Current device:\", paddle.get_device())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "253e818a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/tom/.paddlex/official_models/PP-DocLayoutV2`.\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/tom/.paddlex/official_models/RT-DETR-L_wired_table_cell_det`.\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/tom/.paddlex/official_models/PP-OCRv5_server_det`.\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/home/tom/.paddlex/official_models/PP-OCRv5_mobile_rec`.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "img_path = r\"/media/tom/Code/pcb_defect/ProdVision_Server/media/data_test/1507.05717v1_page-0005.jpg\"\n",
    "layout_model = get_layout_model()\n",
    "table_model = get_table_model()\n",
    "text_det_model = get_text_det_model()\n",
    "text_rec_model = get_text_rec_model()\n",
    "\n",
    "# layout = layout_model.predict(img_path, batch_size=1, layout_nms=True)\n",
    "\n",
    "# tables = table_model.predict(img_path, threshold=0.3, batch_size=1)\n",
    "\n",
    "# text_det = text_det_model.predict(img_path, batch_size=1)\n",
    "\n",
    "# text_lines = text_rec_model.predict(text_det, batch_size=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ec5124",
   "metadata": {},
   "source": [
    "# analysis layout\n",
    "- extract object paragrap\n",
    "- merge paragrap by ( y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a49290fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def extract_patches(layout, img_path):\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    data = layout[0][\"boxes\"]\n",
    "\n",
    "    # Tạo tất cả patch\n",
    "    patches = [{\n",
    "        \"patch_id\": i,\n",
    "        \"patch_label\": bbox[\"label\"],\n",
    "        \"patch_positition\": [int(c) for c in bbox[\"coordinate\"]],\n",
    "        \"patch_score\": bbox[\"score\"],\n",
    "        \"patch\": img[int(bbox[\"coordinate\"][1]):int(bbox[\"coordinate\"][3]),\n",
    "                     int(bbox[\"coordinate\"][0]):int(bbox[\"coordinate\"][2])]\n",
    "    } for i, bbox in enumerate(data)]\n",
    "\n",
    "    # Hàm merge các patch text liên tiếp\n",
    "    def merge_text_patches(patch_group):\n",
    "        xs = [x for p in patch_group for x in (p[\"patch_positition\"][0], p[\"patch_positition\"][2])]\n",
    "        ys = [y for p in patch_group for y in (p[\"patch_positition\"][1], p[\"patch_positition\"][3])]\n",
    "        scores = [p[\"patch_score\"] for p in patch_group]\n",
    "\n",
    "        new_position = [min(xs), min(ys), max(xs), max(ys)]\n",
    "        x1, y1, x2, y2 = map(int, new_position)\n",
    "        merged_patch = img[y1:y2, x1:x2]\n",
    "\n",
    "        return {\n",
    "            \"patch_id\": patch_group[0][\"patch_id\"],\n",
    "            \"patch_label\": \"text\",\n",
    "            \"patch_positition\": new_position,\n",
    "            \"patch_score\": max(scores),\n",
    "            \"patch\": merged_patch\n",
    "        }\n",
    "\n",
    "    # Merge patch text liên tiếp\n",
    "    finally_patches = []\n",
    "    temp_patches = []\n",
    "\n",
    "    for patch in patches:\n",
    "        if patch[\"patch_label\"] == \"text\":\n",
    "            temp_patches.append(patch)\n",
    "        else:\n",
    "            if temp_patches:\n",
    "                finally_patches.append(merge_text_patches(temp_patches))\n",
    "                temp_patches = []\n",
    "            finally_patches.append(patch)\n",
    "\n",
    "    if temp_patches:\n",
    "        finally_patches.append(merge_text_patches(temp_patches))\n",
    "\n",
    "    return finally_patches\n",
    "# patch_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a01c24",
   "metadata": {},
   "source": [
    "# sort list poly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f5853c",
   "metadata": {},
   "source": [
    "# warped polys to patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3d9b5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def warp_polys_to_patches(text_det):\n",
    "    \"\"\"\n",
    "    Từ kết quả text detection, sort polygon theo trục y, warp từng polygon thành patch chữ nhật.\n",
    "    \n",
    "    Args:\n",
    "        text_det: output của text_det_model.predict, dạng list/dict như text_det[0]\n",
    "    \n",
    "    Returns:\n",
    "        warped_patches: list các dict, mỗi dict gồm:\n",
    "            - 'patch': patch ảnh đã warp\n",
    "            - 'bboxes': bbox trong patch\n",
    "            - 'poly': polygon sau warp (int)\n",
    "    \"\"\"\n",
    "    list_poly = text_det[0][\"dt_polys\"]\n",
    "    img_input = text_det[0][\"input_img\"]\n",
    "\n",
    "    centers_y = np.array([np.mean(np.array(poly)[:,1]) for poly in list_poly])\n",
    "    sorted_idx = np.argsort(centers_y)\n",
    "    list_poly_sorted = [list_poly[i] for i in sorted_idx]\n",
    "\n",
    "    warped_patches = []\n",
    "\n",
    "    for poly in list_poly_sorted:\n",
    "        poly = np.array(poly, dtype=np.float32)\n",
    "\n",
    "        if len(poly) > 4:\n",
    "            hull = cv2.convexHull(poly).squeeze()\n",
    "            src_pts = hull[:4] if hull.shape[0] >= 4 else hull\n",
    "        else:\n",
    "            src_pts = poly\n",
    "\n",
    "        while src_pts.shape[0] < 4:\n",
    "            src_pts = np.vstack([src_pts, src_pts[-1]])\n",
    "\n",
    "        min_x, min_y = src_pts.min(axis=0)\n",
    "        max_x, max_y = src_pts.max(axis=0)\n",
    "        width = int(max_x - min_x)\n",
    "        height = int(max_y - min_y)\n",
    "        dst_pts = np.array([[0,0],[width-1,0],[width-1,height-1],[0,height-1]], dtype=np.float32)\n",
    "\n",
    "        M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
    "        warped = cv2.warpPerspective(img_input, M, (width, height))\n",
    "\n",
    "        poly_warped = cv2.perspectiveTransform(src_pts.reshape(-1,1,2), M).reshape(-1,2)\n",
    "        min_x_w, min_y_w = poly_warped.min(axis=0)\n",
    "        max_x_w, max_y_w = poly_warped.max(axis=0)\n",
    "        bbox = [int(min_x_w), int(min_y_w), int(max_x_w), int(max_y_w)]\n",
    "\n",
    "        warped_patches.append({\n",
    "            \"patch\": warped,\n",
    "            \"bboxes\": bbox,\n",
    "            \"poly\": poly_warped.astype(int)\n",
    "        })\n",
    "\n",
    "    return warped_patches\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd76569",
   "metadata": {},
   "source": [
    "# Text recognization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c31adecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recognize_text_from_patches(warped_patches, text_rec_model, batch_size=1):\n",
    "    \"\"\"\n",
    "    Duyệt qua danh sách patch, predict text và trả về list dict gồm text, bbox, score, font.\n",
    "\n",
    "    Args:\n",
    "        warped_patches: list các dict, mỗi dict gồm 'patch', 'bboxes', 'poly'\n",
    "        text_rec_model: model nhận dạng text\n",
    "        batch_size: batch size khi predict\n",
    "\n",
    "    Returns:\n",
    "        text_patch: list dict, mỗi dict gồm 'text', 'bbox', 'score', 'front'\n",
    "    \"\"\"\n",
    "    text_patch = []\n",
    "\n",
    "    for patch_dict in warped_patches:\n",
    "        img = patch_dict['patch']\n",
    "        text_lines = text_rec_model.predict(img, batch_size=batch_size)\n",
    "\n",
    "        result = {\n",
    "            \"text\": text_lines[0][\"rec_text\"],\n",
    "            \"bbox\": patch_dict['bboxes'],\n",
    "            \"score\": text_lines[0][\"rec_score\"],\n",
    "            \"front\": text_lines[0][\"vis_font\"]\n",
    "        }\n",
    "\n",
    "        text_patch.append(result)\n",
    "\n",
    "    return text_patch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b10e6b",
   "metadata": {},
   "source": [
    "# Table processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718c98c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_table_fast(patch, table_model,text_det_model, text_rec_model):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61791b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_document(\n",
    "    img_path,\n",
    "    layout_model,\n",
    "    text_det_model,\n",
    "    text_rec_model,\n",
    "    table_model\n",
    "):\n",
    "\n",
    "    # 1. Layout detection\n",
    "    layout_result = layout_model.predict(\n",
    "        img_path,\n",
    "        batch_size=1,\n",
    "        layout_nms=True\n",
    "    )\n",
    "\n",
    "    # 2. Merge layout patches\n",
    "    merged_patches = extract_patches(layout_result, img_path)\n",
    "\n",
    "    document_paragraphs = []\n",
    "\n",
    "    for patch_info in merged_patches:\n",
    "        patch_img = patch_info[\"patch\"]\n",
    "        patch_idx = patch_info[\"patch_id\"]\n",
    "        patch_type = patch_info[\"patch_label\"]\n",
    "        patch_coords = patch_info[\"patch_positition\"]\n",
    "        patch_conf = patch_info[\"patch_score\"]\n",
    "\n",
    "        # 3. Process by patch type\n",
    "        if patch_type == \"table\":\n",
    "            table_result = extract_table_fast(\n",
    "                img=patch_img,\n",
    "                table_det_model=table_model,\n",
    "                text_det_model = text_det_model,\n",
    "                text_rec_model=text_rec_model\n",
    "            )\n",
    "            import json\n",
    "            print(table_result)\n",
    "\n",
    "            # table_result['text_dict'] = table_result['text_dict'].apply(lambda x: json.loads(x) if isinstance(x, str) else x)\n",
    "\n",
    "\n",
    "            recognized_text = df_to_json_label_value(table_result)\n",
    "        else:\n",
    "            det_result = text_det_model.predict(\n",
    "                patch_img,\n",
    "                batch_size=1\n",
    "            )\n",
    "\n",
    "            rectified_patches = warp_polys_to_patches(\n",
    "                det_result\n",
    "            )\n",
    "\n",
    "            recognized_text = recognize_text_from_patches(\n",
    "                rectified_patches,\n",
    "                text_rec_model\n",
    "            )\n",
    "\n",
    "        # 4. Collect result\n",
    "        paragraph_entry = {\n",
    "            \"patch_id\": patch_idx,\n",
    "            \"patch_label\": patch_type,\n",
    "            \"patch_position\": patch_coords,\n",
    "            \"patch_score\": patch_conf,\n",
    "            \"text_dict\": recognized_text\n",
    "        }\n",
    "\n",
    "        document_paragraphs.append(paragraph_entry)\n",
    "\n",
    "    return document_paragraphs\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0fd8607c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     0                        1                             2\n",
      "0                 Type          Confi gurations                          None\n",
      "1        Transcription                     None                          None\n",
      "2   Bidirectional-LSTM        #hidden units:256                            TM\n",
      "3   Bidirectional-LSTM        #hidden units:256                            TM\n",
      "4      Map-to-Sequence                       ce                          None\n",
      "5          Convolution                        #  #maps:512, k:2 × 2, s:1, p:0\n",
      "6           MaxPooling        Window:1 × 2, s:2                          None\n",
      "7   BatchNormalization                      ion                          None\n",
      "8          Convolution                        #  #maps:512, k:3 × 3, s:1, p:1\n",
      "9   BatchNormalization                      ion                          None\n",
      "10         Convolution                        #  #maps:512, k:3 × 3, s:1, p:1\n",
      "11          MaxPooling        Window:1 × 2, s:2                          None\n",
      "12         Convolution                        #  #maps:256, k:3 × 3, s:1, p:1\n",
      "13         Convolution                        #  #maps:256, k:3 × 3, s:1, p:1\n",
      "14          MaxPooling        Window:2 × 2, s:2                          None\n",
      "15         Convolution                        #  #maps:128, k:3 × 3, s:1, p:1\n",
      "16          MaxPooling        Window:2 × 2, s:2                          None\n",
      "17         Convolution                        #   #maps:64, k:3 × 3, s:1, p:1\n",
      "18               Input  W × 32 gray-scale image                          None\n"
     ]
    }
   ],
   "source": [
    "img_path = \"/media/tom/Code/pcb_defect/ProdVision_Server/media/data_test/1507.05717v1_page-0005.jpg\"\n",
    "\n",
    "\n",
    "# Access individual dimensions\n",
    "document_paragraphs = process_document(\n",
    "    img_path=img_path,\n",
    "    layout_model=layout_model,\n",
    "    text_det_model=text_det_model,\n",
    "    text_rec_model=text_rec_model,\n",
    "    table_model=table_model\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d4badb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'patch_id': 0,\n",
       "  'patch_label': 'text',\n",
       "  'patch_position': [195, 305, 1203, 1301],\n",
       "  'patch_score': 0.9885912537574768,\n",
       "  'text_dict': [{'text': 'where yi is the sequence produced by the recurrent and con-',\n",
       "    'bbox': [0, 0, 988, 43],\n",
       "    'score': 0.9841119050979614,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'volutional layers from Ii. This objective function calculates',\n",
       "    'bbox': [0, 0, 991, 47],\n",
       "    'score': 0.982840359210968,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'a cost value directly from an image and its ground truth',\n",
       "    'bbox': [0, 0, 991, 43],\n",
       "    'score': 0.9845973253250122,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'label sequence. Therefore, the network can be end-to-end',\n",
       "    'bbox': [0, 0, 991, 45],\n",
       "    'score': 0.9842114448547363,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'trained on pairs of images and sequences, eliminating the',\n",
       "    'bbox': [0, 0, 991, 44],\n",
       "    'score': 0.9859133362770081,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'procedure of manually labeling all individual components',\n",
       "    'bbox': [0, 0, 991, 44],\n",
       "    'score': 0.9865004420280457,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'in training images.',\n",
       "    'bbox': [0, 0, 317, 45],\n",
       "    'score': 0.9988006949424744,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'The network is trained with stochastic gradient descent',\n",
       "    'bbox': [0, 0, 945, 48],\n",
       "    'score': 0.9909049868583679,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': '(SGD). Gradients are calculated by the back-propagation al-',\n",
       "    'bbox': [0, 0, 989, 44],\n",
       "    'score': 0.9940615892410278,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'gorithm. In particular, in the transcription layer, error dif-',\n",
       "    'bbox': [0, 0, 988, 43],\n",
       "    'score': 0.983465313911438,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'ferentials are back-propagated with the forward-backward',\n",
       "    'bbox': [0, 0, 993, 46],\n",
       "    'score': 0.9844364523887634,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'algorithm, as described in [15]. In the recurrent layers, the',\n",
       "    'bbox': [0, 0, 992, 46],\n",
       "    'score': 0.9912057518959045,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'Back-Propagation Through Time (BPTT) is applied to cal-',\n",
       "    'bbox': [0, 0, 991, 45],\n",
       "    'score': 0.9902961850166321,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'culate the error differentials.',\n",
       "    'bbox': [0, 0, 474, 38],\n",
       "    'score': 0.9935334324836731,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'For optimization, we use the ADADELTA [37] to au-',\n",
       "    'bbox': [0, 0, 941, 43],\n",
       "    'score': 0.9787776470184326,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'tomatically calculate per-dimension learning rates. Com-',\n",
       "    'bbox': [0, 0, 991, 44],\n",
       "    'score': 0.9840084314346313,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'pared with the conventional momentum [31] method,',\n",
       "    'bbox': [0, 0, 994, 46],\n",
       "    'score': 0.9770667552947998,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'ADADELTA requires no manual setting of a learning',\n",
       "    'bbox': [0, 0, 993, 45],\n",
       "    'score': 0.9847778081893921,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'rate. More importantly, we find that optimization using',\n",
       "    'bbox': [0, 0, 991, 43],\n",
       "    'score': 0.9817352294921875,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'ADADELTA converges faster than the momentum method.',\n",
       "    'bbox': [0, 0, 988, 41],\n",
       "    'score': 0.9874778389930725,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>}]},\n",
       " {'patch_id': 3,\n",
       "  'patch_label': 'paragraph_title',\n",
       "  'patch_position': [199, 1340, 538, 1397],\n",
       "  'patch_score': 0.9362549185752869,\n",
       "  'text_dict': [{'text': '3. Experiments',\n",
       "    'bbox': [0, 0, 322, 42],\n",
       "    'score': 0.9947844743728638,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>}]},\n",
       " {'patch_id': 4,\n",
       "  'patch_label': 'text',\n",
       "  'patch_position': [195, 1425, 1203, 1926],\n",
       "  'patch_score': 0.9887940287590027,\n",
       "  'text_dict': [{'text': 'To evaluate the effectiveness of the proposed CRNN',\n",
       "    'bbox': [0, 0, 939, 41],\n",
       "    'score': 0.9785956740379333,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'model, we conducted experiments on standard benchmarks',\n",
       "    'bbox': [0, 0, 985, 42],\n",
       "    'score': 0.9868367314338684,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'for scene text recognition and musical score recognition,',\n",
       "    'bbox': [0, 0, 988, 41],\n",
       "    'score': 0.9791666865348816,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'which are both challenging vision tasks. The datasets and',\n",
       "    'bbox': [0, 0, 987, 41],\n",
       "    'score': 0.9888548851013184,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'setting for training and testing are given in Sec. 3.1, the de-',\n",
       "    'bbox': [0, 0, 987, 43],\n",
       "    'score': 0.985643744468689,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'tailed settings of CRNN for scene text images is provided',\n",
       "    'bbox': [0, 0, 990, 43],\n",
       "    'score': 0.9897933006286621,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'in Sec. 3.2, and the results with the comprehensive compar-',\n",
       "    'bbox': [0, 0, 990, 50],\n",
       "    'score': 0.9866915941238403,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'isons are reported in Sec. 3.3. To further demonstrate the',\n",
       "    'bbox': [0, 0, 990, 41],\n",
       "    'score': 0.991485595703125,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'generality of CRNN, we verify the proposed algorithm on a',\n",
       "    'bbox': [0, 0, 993, 46],\n",
       "    'score': 0.9898152947425842,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'music score recognition task in Sec. 3.4.',\n",
       "    'bbox': [0, 0, 675, 44],\n",
       "    'score': 0.9703541398048401,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>}]},\n",
       " {'patch_id': 5,\n",
       "  'patch_label': 'paragraph_title',\n",
       "  'patch_position': [198, 1950, 464, 2001],\n",
       "  'patch_score': 0.936479389667511,\n",
       "  'text_dict': [{'text': '3.1. Datasets',\n",
       "    'bbox': [0, 0, 255, 44],\n",
       "    'score': 0.9928405284881592,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>}]},\n",
       " {'patch_id': 6,\n",
       "  'patch_label': 'text',\n",
       "  'patch_position': [195, 2028, 1203, 2977],\n",
       "  'patch_score': 0.9889647960662842,\n",
       "  'text_dict': [{'text': 'For all the experiments for scene text recognition, we',\n",
       "    'bbox': [0, 0, 941, 44],\n",
       "    'score': 0.9816276431083679,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'use the synthetic dataset (Synth) released by Jaderberg et',\n",
       "    'bbox': [0, 0, 993, 45],\n",
       "    'score': 0.9841917157173157,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'al. [20] as the training data. The dataset contains 8 millions',\n",
       "    'bbox': [0, 0, 990, 43],\n",
       "    'score': 0.9721846580505371,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'training images and their corresponding ground truth words.',\n",
       "    'bbox': [0, 0, 987, 41],\n",
       "    'score': 0.9866990447044373,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'Such images are generated by a synthetic text engine and',\n",
       "    'bbox': [0, 0, 991, 45],\n",
       "    'score': 0.9882788062095642,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'are highly realistic. Our network is trained on the synthetic',\n",
       "    'bbox': [0, 0, 989, 42],\n",
       "    'score': 0.9902013540267944,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'data once, and tested on all other real-world test datasets',\n",
       "    'bbox': [0, 0, 987, 38],\n",
       "    'score': 0.9777527451515198,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'without any fine-tuning on their training data. Even though',\n",
       "    'bbox': [0, 0, 988, 41],\n",
       "    'score': 0.9971848726272583,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'the CRNN model is purely trained with synthetic text data,',\n",
       "    'bbox': [0, 0, 991, 45],\n",
       "    'score': 0.9900726675987244,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': ' it works well on real images from standard text recognition',\n",
       "    'bbox': [0, 0, 994, 48],\n",
       "    'score': 0.968618631362915,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'benchmarks.',\n",
       "    'bbox': [0, 0, 217, 39],\n",
       "    'score': 0.9996518492698669,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'Four popular benchmarks for scene text recognition are',\n",
       "    'bbox': [0, 0, 943, 44],\n",
       "    'score': 0.9931758642196655,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'used for performance evaluation, namely ICDAR 2003',\n",
       "    'bbox': [0, 0, 992, 45],\n",
       "    'score': 0.9810880422592163,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': '(IC03), ICDAR 2013 (IC13), IIIT 5k-word (IIIT5k), and',\n",
       "    'bbox': [0, 0, 989, 45],\n",
       "    'score': 0.9772663712501526,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'Street View Text (SVT).',\n",
       "    'bbox': [0, 0, 408, 41],\n",
       "    'score': 0.9890088438987732,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'IC03 [27] test dataset contains 251 scene images with la-',\n",
       "    'bbox': [0, 0, 937, 41],\n",
       "    'score': 0.9873849749565125,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'beled text bounding boxes. Following Wang et al. [34], we',\n",
       "    'bbox': [0, 0, 990, 41],\n",
       "    'score': 0.9922217130661011,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'ignore images that either contain non-alphanumeric charac-',\n",
       "    'bbox': [0, 0, 989, 41],\n",
       "    'score': 0.9911683797836304,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'ters or have less than three characters, and get a test set with',\n",
       "    'bbox': [0, 0, 991, 42],\n",
       "    'score': 0.9782102108001709,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>}]},\n",
       " {'patch_id': 9,\n",
       "  'patch_label': 'figure_title',\n",
       "  'patch_position': [1273, 290, 2278, 425],\n",
       "  'patch_score': 0.9716778993606567,\n",
       "  'text_dict': [{'text': 'Table 1. Network configuration summary. The first row is the top',\n",
       "    'bbox': [0, 0, 986, 36],\n",
       "    'score': 0.9697068333625793,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': \"layer. 'k', 's'and 'p'stand for kernel size, stride and padding size\",\n",
       "    'bbox': [0, 0, 987, 36],\n",
       "    'score': 0.9754424095153809,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'respectively',\n",
       "    'bbox': [0, 0, 180, 32],\n",
       "    'score': 0.9998180270195007,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>}]},\n",
       " {'patch_id': 10,\n",
       "  'patch_label': 'table',\n",
       "  'patch_position': [1395, 424, 2156, 1220],\n",
       "  'patch_score': 0.9876899719238281,\n",
       "  'text_dict': '[\\n  [\\n    {\\n      \"label\": 0,\\n      \"value\": \"Type\"\\n    },\\n    {\\n      \"label\": 1,\\n      \"value\": \"Confi gurations\"\\n    },\\n    {\\n      \"label\": 2,\\n      \"value\": null\\n    }\\n  ],\\n  [\\n    {\\n      \"label\": 0,\\n      \"value\": \"Transcription\"\\n    },\\n    {\\n      \"label\": 1,\\n      \"value\": null\\n    },\\n    {\\n      \"label\": 2,\\n      \"value\": null\\n    }\\n  ],\\n  [\\n    {\\n      \"label\": 0,\\n      \"value\": \"Bidirectional-LSTM\"\\n    },\\n    {\\n      \"label\": 1,\\n      \"value\": \"#hidden units:256\"\\n    },\\n    {\\n      \"label\": 2,\\n      \"value\": \"TM\"\\n    }\\n  ],\\n  [\\n    {\\n      \"label\": 0,\\n      \"value\": \"Bidirectional-LSTM\"\\n    },\\n    {\\n      \"label\": 1,\\n      \"value\": \"#hidden units:256\"\\n    },\\n    {\\n      \"label\": 2,\\n      \"value\": \"TM\"\\n    }\\n  ],\\n  [\\n    {\\n      \"label\": 0,\\n      \"value\": \"Map-to-Sequence\"\\n    },\\n    {\\n      \"label\": 1,\\n      \"value\": \"ce\"\\n    },\\n    {\\n      \"label\": 2,\\n      \"value\": null\\n    }\\n  ],\\n  [\\n    {\\n      \"label\": 0,\\n      \"value\": \"Convolution\"\\n    },\\n    {\\n      \"label\": 1,\\n      \"value\": \"#\"\\n    },\\n    {\\n      \"label\": 2,\\n      \"value\": \"#maps:512, k:2 × 2, s:1, p:0\"\\n    }\\n  ],\\n  [\\n    {\\n      \"label\": 0,\\n      \"value\": \"MaxPooling\"\\n    },\\n    {\\n      \"label\": 1,\\n      \"value\": \"Window:1 × 2, s:2\"\\n    },\\n    {\\n      \"label\": 2,\\n      \"value\": null\\n    }\\n  ],\\n  [\\n    {\\n      \"label\": 0,\\n      \"value\": \"BatchNormalization\"\\n    },\\n    {\\n      \"label\": 1,\\n      \"value\": \"ion\"\\n    },\\n    {\\n      \"label\": 2,\\n      \"value\": null\\n    }\\n  ],\\n  [\\n    {\\n      \"label\": 0,\\n      \"value\": \"Convolution\"\\n    },\\n    {\\n      \"label\": 1,\\n      \"value\": \"#\"\\n    },\\n    {\\n      \"label\": 2,\\n      \"value\": \"#maps:512, k:3 × 3, s:1, p:1\"\\n    }\\n  ],\\n  [\\n    {\\n      \"label\": 0,\\n      \"value\": \"BatchNormalization\"\\n    },\\n    {\\n      \"label\": 1,\\n      \"value\": \"ion\"\\n    },\\n    {\\n      \"label\": 2,\\n      \"value\": null\\n    }\\n  ],\\n  [\\n    {\\n      \"label\": 0,\\n      \"value\": \"Convolution\"\\n    },\\n    {\\n      \"label\": 1,\\n      \"value\": \"#\"\\n    },\\n    {\\n      \"label\": 2,\\n      \"value\": \"#maps:512, k:3 × 3, s:1, p:1\"\\n    }\\n  ],\\n  [\\n    {\\n      \"label\": 0,\\n      \"value\": \"MaxPooling\"\\n    },\\n    {\\n      \"label\": 1,\\n      \"value\": \"Window:1 × 2, s:2\"\\n    },\\n    {\\n      \"label\": 2,\\n      \"value\": null\\n    }\\n  ],\\n  [\\n    {\\n      \"label\": 0,\\n      \"value\": \"Convolution\"\\n    },\\n    {\\n      \"label\": 1,\\n      \"value\": \"#\"\\n    },\\n    {\\n      \"label\": 2,\\n      \"value\": \"#maps:256, k:3 × 3, s:1, p:1\"\\n    }\\n  ],\\n  [\\n    {\\n      \"label\": 0,\\n      \"value\": \"Convolution\"\\n    },\\n    {\\n      \"label\": 1,\\n      \"value\": \"#\"\\n    },\\n    {\\n      \"label\": 2,\\n      \"value\": \"#maps:256, k:3 × 3, s:1, p:1\"\\n    }\\n  ],\\n  [\\n    {\\n      \"label\": 0,\\n      \"value\": \"MaxPooling\"\\n    },\\n    {\\n      \"label\": 1,\\n      \"value\": \"Window:2 × 2, s:2\"\\n    },\\n    {\\n      \"label\": 2,\\n      \"value\": null\\n    }\\n  ],\\n  [\\n    {\\n      \"label\": 0,\\n      \"value\": \"Convolution\"\\n    },\\n    {\\n      \"label\": 1,\\n      \"value\": \"#\"\\n    },\\n    {\\n      \"label\": 2,\\n      \"value\": \"#maps:128, k:3 × 3, s:1, p:1\"\\n    }\\n  ],\\n  [\\n    {\\n      \"label\": 0,\\n      \"value\": \"MaxPooling\"\\n    },\\n    {\\n      \"label\": 1,\\n      \"value\": \"Window:2 × 2, s:2\"\\n    },\\n    {\\n      \"label\": 2,\\n      \"value\": null\\n    }\\n  ],\\n  [\\n    {\\n      \"label\": 0,\\n      \"value\": \"Convolution\"\\n    },\\n    {\\n      \"label\": 1,\\n      \"value\": \"#\"\\n    },\\n    {\\n      \"label\": 2,\\n      \"value\": \"#maps:64, k:3 × 3, s:1, p:1\"\\n    }\\n  ],\\n  [\\n    {\\n      \"label\": 0,\\n      \"value\": \"Input\"\\n    },\\n    {\\n      \"label\": 1,\\n      \"value\": \"W × 32 gray-scale image\"\\n    },\\n    {\\n      \"label\": 2,\\n      \"value\": null\\n    }\\n  ]\\n]'},\n",
       " {'patch_id': 11,\n",
       "  'patch_label': 'text',\n",
       "  'patch_position': [1272, 1310, 2281, 2015],\n",
       "  'patch_score': 0.9861668944358826,\n",
       "  'text_dict': [{'text': '860 cropped text images. Each test image is associated with',\n",
       "    'bbox': [0, 0, 989, 44],\n",
       "    'score': 0.9873338341712952,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'a 50-words lexicon which is defined by Wang et al. [34]. A',\n",
       "    'bbox': [0, 0, 989, 43],\n",
       "    'score': 0.9903266429901123,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'full lexicon is built by combining all the per-image lexi-',\n",
       "    'bbox': [0, 0, 989, 43],\n",
       "    'score': 0.9725096225738525,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'cons. In addition, we use a 50k words lexicon consisting of',\n",
       "    'bbox': [0, 0, 992, 44],\n",
       "    'score': 0.9948133230209351,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'the words in the Hunspell spell-checking dictionary [1].',\n",
       "    'bbox': [0, 0, 931, 47],\n",
       "    'score': 0.9846919775009155,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'IC13 [24] test dataset inherits most of its data from IC03.',\n",
       "    'bbox': [0, 0, 941, 43],\n",
       "    'score': 0.9892326593399048,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'It contains 1,015 ground truths cropped word images.',\n",
       "    'bbox': [0, 0, 892, 42],\n",
       "    'score': 0.9968389868736267,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'IIT5k [28] contains 3,000 cropped word test images',\n",
       "    'bbox': [0, 0, 942, 48],\n",
       "    'score': 0.967510998249054,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'collected from the Internet. Each image has been associ-',\n",
       "    'bbox': [0, 0, 987, 43],\n",
       "    'score': 0.9863153100013733,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'ated to a 50-words lexicon and a 1k-words lexicon.',\n",
       "    'bbox': [0, 0, 849, 41],\n",
       "    'score': 0.9899134635925293,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'SVT [34] test dataset consists of 249 street view images',\n",
       "    'bbox': [0, 0, 943, 48],\n",
       "    'score': 0.9730411171913147,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'collected from Google Street View. From them 647 word',\n",
       "    'bbox': [0, 0, 993, 46],\n",
       "    'score': 0.9765057563781738,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'images are cropped. Each word image has a 50 words lexi-',\n",
       "    'bbox': [0, 0, 989, 46],\n",
       "    'score': 0.9848345518112183,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'con defined by Wang et al. [34].',\n",
       "    'bbox': [0, 0, 543, 48],\n",
       "    'score': 0.9787458181381226,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>}]},\n",
       " {'patch_id': 15,\n",
       "  'patch_label': 'paragraph_title',\n",
       "  'patch_position': [1276, 2047, 1833, 2100],\n",
       "  'patch_score': 0.9461008310317993,\n",
       "  'text_dict': [{'text': '3.2. Implementation Details',\n",
       "    'bbox': [0, 0, 544, 43],\n",
       "    'score': 0.9983920454978943,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>}]},\n",
       " {'patch_id': 16,\n",
       "  'patch_label': 'text',\n",
       "  'patch_position': [1271, 2127, 2283, 2974],\n",
       "  'patch_score': 0.9891149997711182,\n",
       "  'text_dict': [{'text': 'The network confi guration we use in our experiments',\n",
       "    'bbox': [0, 0, 939, 46],\n",
       "    'score': 0.9741703867912292,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'is summarized in Table 1. The architecture of the con-',\n",
       "    'bbox': [0, 0, 990, 42],\n",
       "    'score': 0.9748736023902893,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'volutional layers is based on the VGG-VeryDeep architec-',\n",
       "    'bbox': [0, 0, 988, 44],\n",
       "    'score': 0.9732860326766968,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'tures [32]. A tweak is made in order to make it suitable',\n",
       "    'bbox': [0, 0, 993, 46],\n",
       "    'score': 0.9634546041488647,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'for recognizing English texts. In the 3rd and the 4th max-',\n",
       "    'bbox': [0, 0, 988, 42],\n",
       "    'score': 0.9779350161552429,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'pooling layers, we adopt 1 × 2 sized rectangular pooling',\n",
       "    'bbox': [0, 0, 991, 45],\n",
       "    'score': 0.9780454635620117,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'windows instead of the conventional squared ones. This',\n",
       "    'bbox': [0, 0, 989, 41],\n",
       "    'score': 0.9854339361190796,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'tweak yields feature maps with larger width, hence longer',\n",
       "    'bbox': [0, 0, 989, 41],\n",
       "    'score': 0.9915111660957336,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'feature sequence. For example, an image containing 10',\n",
       "    'bbox': [0, 0, 993, 47],\n",
       "    'score': 0.9708228707313538,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'characters is typically of size 100 × 32, from which a feature',\n",
       "    'bbox': [0, 0, 990, 41],\n",
       "    'score': 0.9808482527732849,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'sequence 25 frames can be generated. This length exceeds',\n",
       "    'bbox': [0, 0, 990, 46],\n",
       "    'score': 0.9854668974876404,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'the lengths of most English words. On top of that, the rect-',\n",
       "    'bbox': [0, 0, 987, 44],\n",
       "    'score': 0.9876003265380859,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'angular pooling windows yield rectangular receptive fields',\n",
       "    'bbox': [0, 0, 987, 46],\n",
       "    'score': 0.9926683306694031,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': '(illustrated in Fig. 2), which are beneficial for recognizing',\n",
       "    'bbox': [0, 0, 987, 45],\n",
       "    'score': 0.9880345463752747,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': \"some characters that have narrow shapes, such as 'i' and '1'.\",\n",
       "    'bbox': [0, 0, 987, 43],\n",
       "    'score': 0.9668351411819458,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'The network not only has deep convolutional layers, but',\n",
       "    'bbox': [0, 0, 942, 43],\n",
       "    'score': 0.9848682284355164,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>},\n",
       "   {'text': 'also has recurrent layers. Both are known to be hard to',\n",
       "    'bbox': [0, 0, 988, 42],\n",
       "    'score': 0.9792530536651611,\n",
       "    'front': <paddlex.utils.fonts.Font at 0x7b62eb911150>}]}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "432b4489",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfbf94aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "def patch_to_img_text_data(patch_size, list_text):\n",
    "    \"\"\"\n",
    "    patch_size: tuple (W,H)\n",
    "    list_text: list of dict, mỗi dict có keys: text, bbox, front (có thể bỏ qua front)\n",
    "    \"\"\"\n",
    "    W, H = patch_size\n",
    "    patch = Image.new(\"RGB\", (W, H), color=(255, 255, 255))\n",
    "    draw = ImageDraw.Draw(patch)\n",
    "    \n",
    "    for text_ in list_text:\n",
    "        text = text_.get(\"text\", \"\")\n",
    "        bbox_text_line = text_.get(\"bbox\", [0,0,0,0])\n",
    "        x0, y0, x1, y1 = bbox_text_line\n",
    "        \n",
    "        # thử lấy font từ front nếu có, nếu không dùng default\n",
    "        try:\n",
    "            font = ImageFont.truetype(\"arial.ttf\", max(10, y1-y0))\n",
    "        except:\n",
    "            font = ImageFont.load_default()\n",
    "        \n",
    "        # vẽ chữ ở x0, y0\n",
    "        draw.text((x0, y0), text, fill=(0,0,0), font=font)\n",
    "    \n",
    "    return patch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f285266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decode_to_image(patch_list, image_size=(3300, 2550, 3)):\n",
    "    H, W, C = image_size\n",
    "    img = Image.new(\"RGB\", (W, H), color=(255, 255, 255))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    for patch in patch_list:\n",
    "        text_dict = patch.get('text_dict')\n",
    "        if not text_dict:\n",
    "            continue\n",
    "        \n",
    "       \n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "# usage\n",
    "img = decode_to_image(document_paragraphs)\n",
    "img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cf080d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "\n",
    "# img = cv2.imread(\"/media/tom/Code/pcb_defect/ProdVision_Server/media/data_test/1507.05717v1_page-0005.jpg\")\n",
    "\n",
    "# # Get the shape as a tuple (height, width, channels)\n",
    "# image_shape = img.shape\n",
    "# print(f\"Image Shape (H, W, C): {image_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97f071a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "# from ocr.ocr_service import OCRService\n",
    "\n",
    "# img_path = \"/media/tom/Code/pcb_defect/ProdVision_Server/chats/output/1507.05717v1_page-0005_res.jpg\"\n",
    "\n",
    "# ocr = OCRService(device=\"gpu\")\n",
    "\n",
    "# result = ocr.process(img_path)\n",
    "\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0f5f83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tomkey",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
